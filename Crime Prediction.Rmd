---
title: "project1"
output: pdf_document
date: "2024-05-05"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

if (!require(randomForest, quietly = TRUE)) {
    install.packages("randomForest", dependencies = TRUE)
    library(randomForest)
} else {
    library(randomForest)
}

library(caret)
library(Metrics)
library(rpart)
library(randomForest)
library(dplyr)
library(ggplot2)
library(tibble)
# Install and load necessary libraries if not already installed
if (!require("readxl")) install.packages("readxl", dependencies = TRUE)
library(readxl)
if (!require("dplyr")) install.packages("dplyr", dependencies = TRUE)
library(dplyr)
if (!require("ggplot2")) install.packages("ggplot2", dependencies = TRUE)
library(ggplot2)
if (!require("tibble")) install.packages("tibble", dependencies = TRUE)
library(tibble)
# Install the lubridate package if it's not already installed
if (!require(lubridate)) {
    install.packages("lubridate")
    library(lubridate)
} else {
    library(lubridate)
}
```
## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
data <- read.csv("Crime_Data_from_2020_to_Present.csv")
#print(head(data,5))
```


```{r}
colnames(data)
str(data)
dim(data)

```

```{r}
summary(data)
sapply(data, class)
```

Data Cleaning:

```{r}
colSums(is.na(data))
```

```{r}
sapply(data, function(x) length(unique(x)))
```
From the above summary, we can see that most of the column values of Crm.Cd.2,Crm.Cd.3,Crm.Cd.4 are null, Hence dropping those columns/features.

```{r}
# Removing Unnecessary Columns
data <- data %>% select(-c(Crm.Cd.2, Crm.Cd.3, Crm.Cd.4))
dim(data)
#head(data)
```

```{r}
#removing rows with values of Vict.Sex other than 'M', 'F'
data <- data[data$Vict.Sex %in% c('M', 'F'), ]
dim(data)

# Check the first few rows of the dataframe to verify the changes
#head(data,5)
```

Handling other missing value columns
```{r}
# data$Premis.Cd <- ifelse(is.na(data$Premis.Cd), -1, data$Premis.Cd)
# data$Weapon.Used.Cd <- ifelse(is.na(data$Weapon.Used.Cd), -1, data$Weapon.Used.Cd)
 #data$Crm.Cd.1 <- ifelse(is.na(data$Crm.Cd.1), -1, data$Crm.Cd.1)

cols_to_process <- c("Premis.Cd", "Crm.Cd.1","Weapon.Used.Cd")

# Replace empty or NaN values with the mean of respective columns
for (col in cols_to_process) {
  data[[col]] <- ifelse(is.na(data[[col]]) | data[[col]] == "", mean(data[[col]], na.rm = TRUE), data[[col]])
}
colSums(is.na(data))

```

```{r}
#summary(data$Weapon.Used.Cd)

```

```{r}
sum(duplicated(data))
data<-data[!duplicated(data),]
dim(data)
#print(head(data,5))
```


```{r}

# Data Type Conversion
data$Date.Rptd <- as.Date(data$Date.Rptd, format = "%m/%d/%Y")
data$DATE.OCC <- as.Date(data$DATE.OCC, format = "%m/%d/%Y")
data$TIME.OCC <- as.POSIXct(data$TIME.OCC, format = "%H%M", tz = "UTC")

#head(data$Date.Rptd)
#head(data$DATE.OCC)
#head(data$DATE.OCC)
print(head(data,5))
#dim(data)
```
Feature Engineering:

```{r}
category_mapping <- list(
  "Violent Crime" = c(
    "RAPE, FORCIBLE", "ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT", 
    "ROBBERY", "BATTERY - SIMPLE ASSAULT", "CRIMINAL HOMICIDE", 
    "RAPE, ATTEMPTED", "KIDNAPPING", "KIDNAPPING - GRAND ATTEMPT", 
    "MANSLAUGHTER, NEGLIGENT"
  ),
  "Property Crime" = c(
    "THEFT-GRAND ($950.01 & OVER)EXCPT,GUNS,FOWL,LIVESTK,PROD", 
    "BURGLARY", "BURGLARY FROM VEHICLE", "BURGLARY, ATTEMPTED", 
    "VEHICLE - STOLEN", "VANDALISM - FELONY ($400 & OVER, ALL CHURCH VANDALISMS)", 
    "THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND OVER)", 
    "THEFT FROM MOTOR VEHICLE - PETTY ($950 & UNDER)", 
    "THEFT FROM MOTOR VEHICLE - ATTEMPT", "BURGLARY FROM VEHICLE, ATTEMPTED", 
    "TILL TAP - GRAND THEFT ($950.01 & OVER)", "AUTO REPAIR", "VEHICLE, STOLEN - OTHER (MOTORIZED SCOOTERS, BIKES, ETC)","VEHICLE - STOLEN"
  ),
  "Non-Violent Crime" = c(
    "VANDALISM - MISDEAMEANOR ($399 OR UNDER)", "SHOPLIFTING - PETTY THEFT ($950 & UNDER)", 
    "SHOPLIFTING-GRAND THEFT ($950.01 & OVER)", "SHOPLIFTING - ATTEMPT", 
    "THEFT PLAIN - PETTY ($950 & UNDER)", "THEFT FROM PERSON", 
    "THEFT FROM PERSON - ATTEMPT", "SHOTS FIRED AT INHABITED DWELLING", 
    "SHOTS FIRED AT MOVING VEHICLE", "DISCHARGE FIREARMS/SHOTS FIRED", 
    "THEFT PLAIN - ATTEMPT", "CHILD STEALING", "DOCUMENT FORGERY / STOLEN FELONY", 
    "EMBEZZLEMENT, GRAND THEFT ($950.01 & OVER)", "EMBEZZLEMENT, PETTY THEFT ($950 & UNDER)", 
    "RECKLESS DRIVING", "THEFT, COIN MACHINE - PETTY ($950 & UNDER)", 
    "THEFT, COIN MACHINE - ATTEMPT", "TILL TAP - PETTY ($950 & UNDER)", 
    "PICKPOCKET", "PICKPOCKET, ATTEMPT", "PIMPING", "PANDERING", 
    "CONSPIRACY", "CONTRIBUTING", "BOMB SCARE", "FALSE POLICE REPORT", 
    "FAILURE TO YIELD", "DISTURBING THE PEACE", "DRIVING WITHOUT OWNER CONSENT (DWOC)", 
    "DISRUPT SCHOOL", "CRUELTY TO ANIMALS", "ILLEGAL DUMPING", 
    "LYNCHING - ATTEMPTED", "LYNCHING", "DRUNK ROLL", "BRIBERY", 
    "INDECENT EXPOSURE", "DISHONEST EMPLOYEE - PETTY THEFT", 
    "DISHONEST EMPLOYEE - GRAND THEFT", "DISHONEST EMPLOYEE ATTEMPTED THEFT", 
    "DOCUMENT WORTHLESS ($200.01 & OVER)", "DOCUMENT WORTHLESS ($200 & UNDER)", 
    "FALSE IMPRISONMENT", "FIREARMS RESTRAINING ORDER (FIREARMS RO)", 
    "FIREARMS EMERGENCY PROTECTIVE ORDER (FIREARMS EPO)", 
    "CONTEMPT OF COURT", "WEAPONS POSSESSION/BOMBING"
  ),
  "Sexual Crime" = c(
    "SEX OFFENDER REGISTRANT OUT OF COMPLIANCE", "LEWD CONDUCT", 
    "CHILD PORNOGRAPHY", "LEWD/LASCIVIOUS ACTS WITH CHILD", 
    "LEWD CONDUCT", "ORAL COPULATION", 
    "SEX,UNLAWFUL(INC MUTUAL CONSENT, PENETRATION W/ FRGN OBJ)", 
    "SODOMY/SEXUAL CONTACT B/W PENIS OF ONE PERS TO ANUS OTH"
  ),
  "Fraud" = c(
    "EXTORTION", "CREDIT CARDS, FRAUD USE ($950 & UNDER", 
    "CREDIT CARDS, FRAUD USE ($950.01 & OVER)", "EMBEZZLEMENT, PETTY THEFT ($950 & UNDER)", 
    "EMBEZZLEMENT, GRAND THEFT ($950.01 & OVER)", "REPLICA FIREARMS(SALE,DISPLAY,MANUFACTURE OR DISTRIBUTE)", 
    "BIGAMY", "COUNTERFEIT", "CRIMINAL HOMICIDE", 
    "DISHONEST EMPLOYEE - PETTY THEFT", "DRUGS, TO A MINOR", 
    "FORGERY, COUNTERFEITING", "FAILURE TO YIELD", 
    "DOCUMENT WORTHLESS ($200.01 & OVER)", "DRIVING WITHOUT OWNER CONSENT (DWOC)", 
    "FALSE POLICE REPORT", "FAILURE TO YIELD", "FIREARMS EMERGENCY PROTECTIVE ORDER (FIREARMS EPO)", 
    "CHILD ABUSE (PHYSICAL) - AGGRAVATED ASSAULT", "FALSE IMPRISONMENT", 
    "CHILD NEGLECT (SEE 300 W.I.C.)", "HUMAN TRAFFICKING - COMMERCIAL SEX ACTS", 
    "DRUNK ROLL", "HUMAN TRAFFICKING - INVOLUNTARY SERVITUDE", 
    "CHILD ANNOYING (17YRS & UNDER)", "CHILD ABANDONMENT"
  ),
  "Other" = c(
    "BIKE - STOLEN", "THEFT, PERSON", 
    "VIOLATION OF TEMPORARY RESTRAINING ORDER", 
    "VEHICLE - ATTEMPT STOLEN", "ATTEMPTED ROBBERY", 
    "ATTEMPTED ROBBERY", "PICKPOCKET, ATTEMPT", 
    "THREATENING PHONE CALLS/LETTERS", "CHILD ABANDONMENT", 
    "TRESPASSING", "UNAUTHORIZED COMPUTER ACCESS", 
    "VEHICLE - STOLEN", "VIOLATION OF COURT ORDER")
)

map_to_category <- function(crime) {
  for (category in names(category_mapping)) {
    if (crime %in% category_mapping[[category]]) {
      return(category)
    }
  }
  return("Other")
}

data <- data %>%
  mutate(crime_category = sapply(Crm.Cd.Desc, map_to_category))

#unique(data$crime_category)
```

```{r}
#unique(data$Premis.Desc)

# Premis_counts <- table(data$Premis.Desc)
# sorted_Premis_counts <- sort(Premis_counts, decreasing = TRUE)
# top_5_Premis <- names(head(sorted_Premis_counts, 15))
# print(top_5_Premis)
# print(sorted_Premis_counts)
#table(data$sorted_Premis_counts)
```

```{r}
data <- data %>%
  mutate(Weapon.Desc = ifelse(Weapon.Desc == "", "NO WEAPON", Weapon.Desc))

weapon_counts <- table(data$Weapon.Desc)
sorted_weapon_counts <- sort(weapon_counts, decreasing = TRUE)
top_5_weapons <- names(head(sorted_weapon_counts, 5))
data <- data[data$Weapon.Desc %in% top_5_weapons, ]
#print(top_5_weapons)

#head(data,5)
dim(data)
```

```{r}
Premis_counts <- table(data$Premis.Desc)
sorted_Premis_counts <- sort(Premis_counts, decreasing = TRUE)
top_5_Premis <- names(head(sorted_Premis_counts, 15))
data <- data[data$Premis.Desc %in% top_5_Premis, ]
dim(data)
#print(top_5_Premis)
#print(sorted_Premis_counts)
```
```{r}

columns_of_interest <- c("Crm.Cd.Desc","Vict.Age", "Vict.Sex", "Premis.Desc", "crime_category", "Weapon.Desc", "AREA", "AREA.NAME", "TIME.OCC")
unique_values <- lapply(columns_of_interest, function(col) unique(data[[col]]))

check_coverage <- function(sample_data, unique_values, columns_of_interest) {
  for (i in seq_along(columns_of_interest)) {
    col <- columns_of_interest[i]
    unique_set <- unique_values[[i]]
    if (!all(unique_set %in% unique(sample_data[[col]]))) {
      return(FALSE)
    }
  }
  return(TRUE)
}

# Initial random sampling
set.seed(42)
sample_data <- data %>% sample_n(20000)

if (!check_coverage(sample_data, unique_values, columns_of_interest)) {
  for (i in seq_along(columns_of_interest)) {
    col <- columns_of_interest[i]
    unique_set <- unique_values[[i]]
    missing_values <- setdiff(unique_set, unique(sample_data[[col]]))
    if (length(missing_values) > 0) {
      missing_rows <- data %>% filter(data[[col]] %in% missing_values)
      sample_data <- bind_rows(sample_data, missing_rows)
      if (nrow(sample_data) > 20000) {
        sample_data <- sample_data %>% sample_n(20000)
      }
    }
  }
}

# Final sampling to ensure the sample size is exactly 20k
if (nrow(sample_data) > 20000) {
  sample_data <- sample_data %>% sample_n(20000)
}


#write.csv(sample_data, "sample_dataset1.csv", row.names = FALSE)
```

```{r}
unique(sample_data$Vict.Sex)
#table(data$Premis.Desc)
```

```{r}
grouped_area <- sample_data %>% 
  group_by(AREA.NAME) %>% 
  summarise(Count = n())

ggplot(grouped_area, aes(x = AREA.NAME, y = Count)) +
  geom_bar(stat = "identity",fill = 2) +
  ggtitle("Number of Incidents by Area Name") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10), # Rotate and adjust the size of text
        plot.title = element_text(hjust = 0.5))
```

```{r}
crime_desc <- sample_data %>% 
  group_by(Crm.Cd.Desc) %>% 
  summarise(Count = n()) %>% 
  arrange(desc(Count)) %>%  # Sort by Count in descending order
  top_n(5, Count)  # Select the top 5 values

ggplot(crime_desc, aes(x = reorder(Crm.Cd.Desc, Count), y = Count, fill = Crm.Cd.Desc)) + # Reorder the factors for better visualization
  geom_bar(stat = "identity") +
  ggtitle("Top 5 Crime Descriptions") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7, margin = margin(t = 8)),
        plot.title = element_text(hjust = 0.4)) +
  xlab("Crime Description") + 
  ylab("Number of Incidents") +
  scale_fill_manual(values = rainbow(5))
```


```{r}
sample_data$crime_level <- floor(sample_data$Crm.Cd / 100)
detail <- 0.01
sample_data$lon_round <- round(sample_data$LON / detail) * detail
sample_data$lat_round <- round(sample_data$LAT / detail) * detail

# Summarize sample_data for heatmap
df_heatmap <- sample_data %>% 
  group_by(lon_round, lat_round, crime_level) %>% 
  summarise(Count = n())

# Plot the heatmap directly
ggplot(df_heatmap, aes(x = lon_round, y = lat_round, fill = Count)) +
  geom_tile() +
  scale_fill_gradient(low = 4, high = "red") +  # Adjust gradient colors as needed
  labs(x = "Longitude", y = "Latitude", title = "Crime Heatmap")
```


```{r}
#unique(sample_data$Weapon.Desc)
# unique(sample_data$Crm.Cd.Desc)
#Weapon.Desc
#weapon_counts <- table(sample_data$Weapon.Desc)
#head(sort(weapon_counts, decreasing = TRUE), 15)

```


Training and testing:
```{r}
head(sample_data)
```

```{r}
# Load required libraries
library(randomForest)
library(caret)

# Assuming sample_data is your dataframe
# Select features (X) and target variable (Y)
X <- sample_data[, c("Vict.Age", "Vict.Sex", "Premis.Desc", "crime_category", "Weapon.Desc")]
Y <- sample_data$AREA

# Convert categorical variables to factors
X$Vict.Sex <- as.factor(X$Vict.Sex)
X$Premis.Desc <- as.factor(X$Premis.Desc)
X$crime_category <- as.factor(X$crime_category)
X$Weapon.Desc <- as.factor(X$Weapon.Desc)

# Split the data into training and testing sets (80% train, 20% test)
set.seed(42)
trainIndex <- createDataPartition(Y, p = 0.6, list = FALSE)
X_train <- X[trainIndex, ]
X_test <- X[-trainIndex, ]
Y_train <- Y[trainIndex]
Y_test <- Y[-trainIndex]

# Check the structure of the training data
str(X_train)
str(Y_train)

# Initialize and train the Random Forest model
model <- randomForest(x = X_train, y = as.factor(Y_train), ntree = 100, importance = TRUE)

# Predict the test set
Y_pred <- predict(model, X_test)

# Calculate accuracy
accuracy <- mean(Y_pred == Y_test)
print(paste("Accuracy:", accuracy))

# Display the importance of each variable
importance(model)
varImpPlot(model)

```


```{r}
target <- 'case_solved'
# Load the caret package
library(caret)

# Define the features and target variable
X <- data[, features]  # Features
y <- data[, target]    # Target

# Set the random seed for reproducibility
set.seed(42)

# Split the dataset into training and testing sets (80% training, 20% testing)
train_indices <- createDataPartition(y, p = 0.8, list = FALSE)
X_train <- X[train_indices, ]
X_test <- X[-train_indices, ]
y_train <- y[train_indices]
y_test <- y[-train_indices]



# Standardize the features (important for logistic regression)
X_train_scaled <- scale(X_train)
X_test_scaled <- scale(X_test)
head(X_train_scaled)
head(X_test_scaled)
```

```{r}
# Load the randomForest package
library(randomForest)

# Train the random forest classifier
rf_clf <- randomForest(x = X_train, y = y_train)

# Print the trained model
print(rf_clf)
# Make predictions on the testing data
rf_clf_pred <- predict(rf_clf, newdata = X_test)

conf_matrix <- confusionMatrix(rf_clf_pred, y_test)

# Print the accuracy score
print(paste("Random Forest Classifier Accuracy:", conf_matrix$overall['Accuracy']))
```

```{r}
# Load the rpart package
install.packages('rpart')
library(rpart)

# Train the decision tree classifier
tree_clf <- rpart(formula = y_train ~ ., data = X_train)

# Make predictions on the testing data
tree_clf_pred <- predict(tree_clf, newdata = X_test, type = "class")

# Calculate the accuracy of the decision tree classifier
accuracy <- sum(tree_clf_pred == y_test) / length(y_test) * 100

# Print the accuracy
print(paste("Decision Tree Classifier Accuracy:", round(accuracy, 2), "%"))


```

```{r}
# Load the e1071 package for SVM
install.packages('e1071')
library(e1071)

# Train the SVM classifier
svm_clf <- svm(y_train ~ ., data = X_train_scaled_df, kernel = "linear")

# Make predictions on the testing data
svm_pred <- predict(svm_clf, newdata = as.data.frame(X_test_scaled))

# Print the SVM classification accuracy
accuracy <- sum(svm_pred == y_test) / length(y_test) * 100
print(paste("SVM Classifier Accuracy:", round(accuracy, 2), "%"))

# Print the SVM classification report
conf_matrix <- confusionMatrix(svm_pred, y_test)
print("SVM Classification Report:")
print(conf_matrix)

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
